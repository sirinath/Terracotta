#
# All content copyright (c) 2003-2008 Terracotta, Inc.,
# except as may otherwise be noted in a separate copyright notice.
# All rights reserved
#

###########################################################################################
#                                                                                         #
#  This is the default TCProperties that can be accessed from DSO code base by calling    #
#  TCProperties.getProperties().getProperty("key") or one of the Typed methods.           #
#                                                                                         #
#  The values here are the default values that can be overridden by placing a             #
#  tc.properties in the base directory where tc.jar resides at runtime.                   #
#                                                                                         #
###########################################################################################

###########################################################################################
# Section                           : L2 Transaction Manager Properties
# logging.enabled                   : Enable/disable L2's tx mgr logging
# logging.verbose                   : Turns on debug loggings for tx mgr
# logging.printStats                : Enables/disables logging for tx stats
# logging.printCommits              : Enables/disables logging for tx commits
# logging.printBroadCastStats       : Enables/disables logging for tx Broadcasts
# passive.throttle.enabled          : Enables/disables throttling of active from Passive when
#                                     the number of pending txns reaches the threshold
# passive.throttle.threshold        : Number of pending transactions after which passive will
#                                     throttle the active
# passive.throttle.maxSleepSeconds  : Sleep time for active when passive throttles it
# broadcast.durability.level   : Controls level of persistence to ensure before broadcasting the result
#                                   of a transaction.
#                                      - NONE : just send it immediately
#                                      - RELAYED : make sure it's relayed to all passives
#                                      - DISK : make sure it's on disk (only applicable when restartable is on)
###########################################################################################
l2.transactionmanager.logging.enabled = false
l2.transactionmanager.logging.verbose = false
l2.transactionmanager.logging.printStats = true
l2.transactionmanager.logging.printCommits = false
l2.transactionmanager.logging.printBroadcastStats = false
l2.transactionmanager.passive.throttle.enabled = true
l2.transactionmanager.passive.throttle.threshold = 20000
l2.transactionmanager.passive.throttle.maxSleepSeconds= 5
l2.transactionmanager.broadcast.durability.level = RELAYED

###########################################################################################
# Section                       - L2 Object Manager Properties
# Description                   - This section contains the defaults for the object manager of the L2
# maxTxnsInTxnObjectGrouping    - Max number of Transactions allowed in the
#                                 TransactionalObject grouping
# objectrequest.split.size      - Whats the maximum objects that l2 will lookup in one shot
# objectrequest.logging.enabled - Turn on logging to see what object request cache saved
# request.logging.enabled       - Enables/Disables logging of ManagedObject requests from
#                                 clients. If enabled, logs counts of requested instance types
#                                 every 5 seconds.
# persistor.logging.enabled     - Enables/Disables logging of commits to disk while running
#                                 in persistent mode.
# passive.sync.batch.size       - Number of objects in each message that is sent from
#                                 active to passive while synching
# passive.sync.message.maxSizeInMegaBytes - Max Message size of an object sync message to passive
# passive.sync.throttle.timeInMillis - Time to wait before sending the next batch of
#                                 objects to the passive
# l2.objectmanager.passive.sync.throttle.maxPendingMessages - Max object sync messages that can sent
#                  to passive without a ServerTxnAckMessage from the passive.
# dgc.throttle.timeInMillis     - Throttle time for dgc for each cycle for every requestsPerThrottle
#                                 requests for references from object manager
# dgc.throttle.requestsPerThrottle - Number of objects for which object references are requested
#                                    from object manager after which dgc will throttle
# dgc.inline.intervalInSeconds - Interval in seconds at which to delete objects removed by inline dgc
# dgc.inline.cleanup.delaySeconds - Seconds to delay the start of the inline dgc reference cleanup
# data.backup.throttle.timeInMillis - time to sleep between copying of each file from the db
#                                     while taking backup
#
###########################################################################################
l2.objectmanager.maxTxnsInTxnObjectGrouping = 10
l2.objectmanager.objectrequest.split.size = 500
l2.objectmanager.objectrequest.logging.enabled = false
l2.objectmanager.request.logging.enabled = false
l2.objectmanager.persistor.logging.enabled = false
l2.objectmanager.passive.sync.batch.size = 500
l2.objectmanager.passive.sync.message.maxSizeInMegaBytes = 10
l2.objectmanager.passive.sync.throttle.timeInMillis = 0
l2.objectmanager.passive.sync.throttle.maxPendingMessages = 10
l2.objectmanager.dgc.throttle.timeInMillis = 0
l2.objectmanager.dgc.throttle.requestsPerThrottle = 1000
l2.objectmanager.dgc.inline.intervalInSeconds = 10
l2.objectmanager.dgc.inline.maxObjects = 10000
l2.objectmanager.dgc.inline.cleanup.delaySeconds = 0

###########################################################################################
# Section                             : L2 FRS Properties
# Description                         : This section contains configuration for FRS on the L2
# compactor.policy                   : Compactor policy to use. One of LSNGapCompactionPolicy, SizeBasedCompactionPolicy
# compactor.lsnGap.minLoad           : LSNGapCompactionPolicy: lower load threshold before compaction starts.
# compactor.lsnGap.maxLoad           : LSNGapCompactionPolicy: load at which a compaction run stops.
# compactor.sizeBased.threshold      : SizeBasedCompactionPolicy: Start threshold.
# compactor.sizeBased.amount         : SizeBasedCompactionPolicy: Amount to compact per compactor run.
#
###########################################################################################
l2.frs.compactor.lsnGap.minLoad = 0.40
l2.frs.compactor.lsnGap.maxLoad = 0.80

###########################################################################################
# Section                             : L2 Seda stage properties
# Description                         : This section contains configuration for SEDA stages for L2
# apply.stage.threads                 : Number of seda apply stage threads
# search.threads                      : Number of seda search stage threads
# query.threads                       : Number of seda query stage threads
# managedobjectrequeststage.threads   : Number of threads for object request seda stage
#                                       (experimental, do not change)
# managedobjectresponsestage.threads  : Number of threads for object response seda stage
# stage.sink.capacity                 : Capacity of seda stage queue, Integer.MAX_VALUE if not set
#                    (experimental, do not change)
###########################################################################################
#l2.seda.apply.stage.threads = 8
#l2.seda.managedobjectrequeststage.threads = 4
#l2.seda.managedobjectresponsestage.threads = 4
l2.seda.search.threads = 16
l2.seda.query.threads = 4
l2.seda.stage.sink.capacity = -1
l2.seda.evictionprocessorstage.sink.capacity = 1000
l2.seda.local.cache.transaction.complete.threads = 8
l2.seda.local.cache.transaction.complete.sink.capacity = 5000
l2.seda.local.cache.invalidations.sink.capacity = 5000

###########################################################################################
# Section               : L1 Seda stage properties
# Description           : This section contains configuration for SEDA stages for L1
# stage.sink.capacity   : capacity of L1's seda stage queue, Integer.MAX_VALUE if not set
###########################################################################################
l1.seda.stage.sink.capacity = -1

###########################################################################################
# Section :  L2 Bean shell Properties
# Description : Bean shell can be enabled in the server for debugging.
# enabled     :  Enables/disables Beanshell
# port        :   Port number for Beanshell
###########################################################################################
l2.beanshell.enabled = false
l2.beanshell.port = 9929

###########################################################################################
# Section :  Network HA (nha)
# Description : If Networked HA is enabled then these values take effect
#    tcgroupcomm.handshake.timeout  - tc-group-comm handshake timeout milliseconds
#    tcgroupcomm.discovery.interval  - tc-group-comm member discovery interval milliseconds
#    tcgroupcomm.reconnect.enabled  -  Enable L2-L2 reconnect
#    tcgroupcomm.reconnect.timeout  - L2-L2 reconnect windows in milliseconds
#    tcgroupcomm.reconnect.sendqueue.cap - Sendqueue capacity, 0 for Integer.MAX_VALUE
#    tcgroupcomm.reconnect.maxDelayedAcks - At least one ack per maxDelayedAcks messages received
#    tcgroupcomm.reconnect.sendWindow - Max outstanding messages before ack received
#    send.timeout.millis   -  Number of milliseconds to retry sending a message
#    dirtydb.autoDelete    -  Delete old database if any automatically, during passive L2 startup
#    dirtydb.rolling       -  Retain latest rolling number of old databases in the backup directory.
#                                  If 0, all old databases will be retained.
#    autoRestart           -  Automatically restart L2 when it goes down (on few cases only.
#                                  like zap node errors, dirty database startup problems)
#    dirtydb.backup.enabled-  Creates BackUp of DirtyDB only If it is set to true.
###########################################################################################
l2.nha.tcgroupcomm.handshake.timeout = 5000
l2.nha.tcgroupcomm.discovery.interval = 1000
l2.nha.tcgroupcomm.reconnect.enabled = true
l2.nha.tcgroupcomm.reconnect.timeout = 5000
l2.nha.tcgroupcomm.reconnect.sendqueue.cap = 5000
l2.nha.tcgroupcomm.reconnect.maxDelayedAcks = 16
l2.nha.tcgroupcomm.reconnect.sendWindow = 32
l2.nha.send.timeout.millis = 16000
l2.nha.dirtydb.autoDelete = true
l2.nha.dirtydb.rolling = 0
l2.nha.autoRestart = true
l2.nha.dirtydb.backup.enabled = true

###########################################################################################
# Section                   : L2 Server Array Properties
# serverarray.2pc.enabled   : Enables/disables 2 phase commit for enterprise server array
#                             (experimental, do not change)
###########################################################################################
l2.serverarray.2pc.enabled = true

###########################################################################################
# Section : L1 Server Array Properties
# Description :
# objectCreationStrategy     - Supported types round-robin, group-affinity
# roundRobin.startIndex      - The first index to start at for each client. Supports
#                              sequential, random
# roundRobin.coordinatorLoad - Load to apply to coordinator in % compared to other groups
#                              [0-100], 100 being equal load as others
#
# objectCreationStrategy.groupAffinity- Mirror group name as available in tc-config,
#                                      if group-affinity object creation strategy
#                                      is chosen
###########################################################################################
l1.serverarray.objectCreationStrategy = round-robin
l1.serverarray.objectCreationStrategy.roundRobin.startIndex = sequential
l1.serverarray.objectCreationStrategy.groupAffinity.groupName = mirror-group1

###########################################################################################
# Section                       : Misc L2 Properties
# Description                   : Other Miscellaneous L2 Properties
# enable.legacy.production.mode : If true then L2 will require -force to shutdown an active
#                                 instance in a cluster with no passives present
# startuplock.retries.enabled   : If true then L2s will try to lock indefinitely on the data
#                                 directory while starting up
###########################################################################################
l2.enable.legacy.production.mode = false
l2.startuplock.retries.enabled = false

###########################################################################################
# Section : L1 L2 Config match Property
# Description : This property will check if the client has to match server config
#        i.e. check cluster topology
###########################################################################################
l1.l2.config.validation.enabled = true

###########################################################################################
# Section                   : L1 Memory Manager Properties
# Description               : This section contains the defaults for the cache manager for the L1
# criticalThreshold         : % of memory used after which memory manager will evict aggressively
###########################################################################################
l1.memorymanager.criticalThreshold = 70

###########################################################################################
#    Section                    :  L1 Transaction Manager Properties
#    Description                : This section contains the defaults for the Transaction manager for the L1
#    logging.enabled            : If true, enables some logging in the transaction manager
#    maxOutstandingBatchSize    : The max number of batches of transaction that each L1
#                                 sends to the L2 at once
#    maxBatchSizeInKiloBytes    : The max size of  batches that are send to the L2 from
#                                 the L1. The units is in Kilobytes
#    maxPendingBatches          : The max number of pending batches the client creates
#                                 before a Batch ack is received from the server, after
#                                 which the client stalls until a Batch ack is received.
#    maxSleepTimeBeforeHalt     : The max time that a user thread will wait for L2 to
#                                 catchup if the L2 is behind applying transactions. This
#                                 time is used before maxPendingBatches is reached. The
#                                 units are in milliseconds
#    completedAckFlushTimeout   : The timeout in milliseconds after which a NullTransaction
#                                 is send to the server if completed txn acks are still pending
#    strings.compress.enabled   : Enables string compression when sending to the L2. There
#                                 is a processing overhead at the L1, but saves network
#                                 bandwidth, reduces memory requirements in the L2 and also
#                                 reduces disk io at the L2.
#    strings.compress.minSize   : Strings with lengths less that this number are not
#                                 compressed
#    folding.enabled            : True/false whether txn folding is enabled. Folding is
#                                 the act of combining similar (but unique) application
#                                 transactions into a single txn (for more optimal processing
#                                 on the server). Only transactions that share common locks
#                                 and objects can be folded.
#    folding.lock.limit         : The maximum number of distinct locks permitted in folded txns
#                                 (0 or less means infinite)
#    folding.object.limit       : Object count threshold for short circuiting txn folding logic
#                                 (0 or less means infinite). If a txn contains more distinct
#                                 than this threshold, there will be no search to determine a
#                                 possible fold target
#    folding.debug              : Enable debug logging for the transaction folder. Use with
#                                 care -- This will cause *lots* of logging to occur
#    timeoutForAckOnExit        : Max wait time in seconds to wait for ACKs before exit.
#                                 value 0 for infinite wait.
###########################################################################################
l1.transactionmanager.logging.enabled = false
l1.transactionmanager.maxOutstandingBatchSize = 8
l1.transactionmanager.maxBatchSizeInKiloBytes = 128
l1.transactionmanager.maxPendingBatches = 88
l1.transactionmanager.maxSleepTimeBeforeHalt = 1024
l1.transactionmanager.completedAckFlushTimeout = 5000
l1.transactionmanager.strings.compress.enabled = true
l1.transactionmanager.strings.compress.logging.enabled = false
l1.transactionmanager.strings.compress.minSize = 512
l1.transactionmanager.folding.enabled = true
l1.transactionmanager.folding.object.limit = 0
l1.transactionmanager.folding.lock.limit = 0
l1.transactionmanager.folding.debug = false
l1.transactionmanager.timeoutForAckOnExit=300

###########################################################################################
# Section                           : L1 Connect Properties
# Description                       : This section contains properties controlling L1 connect feature
# socket.connect.timeout            : Socket timeout (ms) when connecting to server
# reconnect.waitInterval            : Sleep time (ms) between trying connections to the server
#                                     (values less than 10ms will be set to 10ms)
###########################################################################################
l1.socket.connect.timeout=10000
l1.socket.reconnect.waitInterval=1000

###########################################################################################
# Section                           : DSO Cluster Events
# outofbandnotifier.jointime.millis : Clusrter event notification thread join time in millis
###########################################################################################
l1.clusterevents.outofbandnotifier.jointime.millis = 100

tc.transport.handshake.timeout=10000
tc.config.getFromSource.timeout=30000
tc.config.total.timeout=300000

###########################################################################################
# Section           : L1 Reconnect Properties
# Description       : This section contains properties controlling L1 reconnect feature
#
# Note that l1 get these properties from l2, so the local copy of l1 doesn't matter
#
# enabled           : If true, enables l1 reconnect feature (and Once-And-Only-Once protocol)
# timeout.millis    : Number of milliseconds a disconnected L1 is allowed to
# sendqueue.cap     : Sendqueue capacity, 0 for Integer.MAX_VALUE
#                     reconnect to L2 that has not crashed
# maxDelayedAcks    : Max number of messages received for which ack may not be sent
# sendWindow        : Max number of messages that can be sent without getting an ack back

###########################################################################################
l2.l1reconnect.enabled = true
l2.l1reconnect.timeout.millis = 5000
l2.l1reconnect.sendqueue.cap = 5000
l2.l1reconnect.maxDelayedAcks = 16
l2.l1reconnect.sendWindow = 32
l2.l1rejoin.sleep.millis = 100

###########################################################################################
# Section                   : L1 Object Manager Properties
# Description               : This section contains the defaults for the Object manager for the L1
# remote.maxDNALRUSize      : Count of dnas after which l1s will remove unrequested object
# remote.logging.enabled    : Enable/disable logging of remote object manager
# remote.maxRequestSentImmediately
#                           : Maximum number of requests send immediately after which it will be batched
# remote.batchLookupTimePeriod
#                           : Time Period in millisecond within which requests are batched after sending
#                             maxRequestSentImmediately number of requests.
# objectid.request.size     : Number of object ids requested at once from L2 for creating
#                             new objects
# flush.logging.enabled     : Enable/disable object's flush logging
# fault.logging.enabled     : Enable/disable object's fault logging
# fault.count               : Default number of additional reachable objects to also fault when requesting a remote object
###########################################################################################
l1.objectmanager.remote.maxDNALRUSize = 60
l1.objectmanager.remote.logging.enabled = false
l1.objectmanager.remote.maxRequestSentImmediately = 4
l1.objectmanager.remote.batchLookupTimePeriod = 1
l1.objectmanager.objectid.request.size = 50000
l1.objectmanager.flush.logging.enabled = false
l1.objectmanager.fault.logging.enabled = false
l1.objectmanager.fault.count = 500

###########################################################################################
# Section                   : L1 ServerMap Manager Properties
# remote.maxRequestSentImmediately
#                           : Maximum number of requests send immediately after which it will be batched
# remote.batchLookupTimePeriod
#                           : Time Period in millisecond within which requests are batched after sending
#                             maxRequestSentImmediately number of requests.
###########################################################################################
l1.servermapmanager.remote.maxRequestSentImmediately = 4
l1.servermapmanager.remote.batchLookupTimePeriod = 1

###########################################################################################
# Section                   : L2 ServerMap Properties
# eviction.clientObjectReferences.refresh.interval
#              : ServerMap Eviction Client Object References refresh interval in milliseconds
# eviction.broadcast.maxkeys
#              : ServerMap Eviction Broadcast Message contain max key count entries
###########################################################################################
l2.servermap.eviction.clientObjectReferences.refresh.interval = 60000
l2.servermap.eviction.broadcast.maxkeys = 10000


###########################################################################################
# Section           : L1 Lock Manager Properties
# Description       : This section contains the defaults for the client lock manager for the L1
# striped.count     : Striping count for l1 lock manager
# timeout.interval  : Time after which an unused lock will be a candidate for lock GC
###########################################################################################
l1.lockmanager.striped.count = 128
l1.lockmanager.timeout.interval = 60000
l1.lockmanager.pinning.enabled = true

###########################################################################################
# Section           :  Common Logging properties for both L1 and L2
# Description       : Logging attributes that can be overridden.
# maxBackups        : The maximum number of backup log files to keep
# maxLogFileSize    : The maximum size of a log file in megabytes
# longgc.threshold  : JVM GC taking greater than the time mentioned will be logged
###########################################################################################
logging.maxBackups = 20
logging.maxLogFileSize = 512
logging.longgc.threshold = 8000

###########################################################################################
# Section                             : Common Stage Monitoring properties for both L1 and L2
# Description                         : Stage monitoring can be enabled or disabled for debugging.
# stage.monitor.enabled               : <true/false>    - Enable or Disable Monitoring
# stage.monitor.delay                 : long            - frequency in milliseconds
# bytebuffer.pooling.enabled          : Enable/disable tc byte buffer pooling
# bytebuffer.common.pool.maxcount     : Max size of pool for tc byte buffer
# bytebuffer.threadlocal.pool.maxcount: Thread pool size
###########################################################################################
tc.stage.monitor.enabled = false
tc.stage.monitor.delay = 5000
tc.bytebuffer.pooling.enabled = true
tc.bytebuffer.common.pool.maxcount = 3000
tc.bytebuffer.threadlocal.pool.maxcount = 2000
tc.messages.grouping.enabled = true
tc.messages.grouping.maxSizeKiloBytes = 1024
tc.messages.packup.enabled = true

###########################################################################################
# Section             :  Common property for TC Management MBean
# Description         : TC Management MBeans can be enabled/disabled
# mbeans.enabled      : <true/false>   - All mbeans enabled/disabled
# test.mbeans.enabled : <true/false>   - Test mode mbeans enabled/disabled
###########################################################################################
tc.management.mbeans.enabled = true
tc.management.test.mbeans.enabled = false

###########################################################################################
# Section :  Session properties (applies to all DSO session enabled web apps in this VM)
#    id.length           : The length (in chars) for session identifiers (min 8)
#    serverid            : The server identifier to place in the session ID
#    delimiter           : The delimiter that separates the server ID from the session ID
#    cookie.domain       : Domain value for session cookie
#    cookie.secure       : Force the secure flag in the session cookie (if false then cookie will be set secure for secure(https) requests)
#    cookie.maxage.seconds : The maximum lifetime of the session cookie
#    cookie.name         : Name of the session cookie
#    cookie.enabled      : Enable / disable the use of cookies for session tracking
#    cookie.httponly     : Enable / disable the httpOnly flag in cookie (servlet API 3.0+ only)
#    maxidle.seconds     : Session idle timeout in seconds
#    tracking.enabled    : Enable / disable session tracking completely
#    urlrewrite.enabled  : Enable / disable the URL functionality
#    attribute.listeners : Comma separated list of HttpSessionAttributeListener classes
#    listeners           : Comma separated list of HttpSessionListener classes
#    invalidator.sleep   : Sleep time between runs of the session invalidator
#    debug.invalidate    : Log session invalidation
#    debug.sessions      : Output additional debug information when sessions are looked up, created, etc
#    copy.on.read        : Deserialize attributes on every call to getAttribute()
#    use.constant.id     : If true the value returned from HttpSession.getId() will be constant throughout the cluster (even though
#                          the value of the underlying session cookie will still include varying server identifiers and delimiters)
###########################################################################################
#session.id.length = 20
#session.serverid =
#session.delimiter =
#session.cookie.domain =
#session.cookie.comment =
#session.cookie.secure = false
#session.cookie.maxage.seconds = -1
#session.cookie.name = JSESSIONID
#session.cookie.path =
#session.cookie.enabled = true
#session.maxidle.seconds = 1800
#session.tracking.enabled = true
#session.urlrewrite.enabled = true
#session.attribute.listeners =
#session.listeners =
#session.use.constant.id = false
session.invalidator.sleep = 300
session.debug.sessions = false
session.debug.invalidate = false


###########################################################################################
# Section :  Memory Monitor
# forcebasic : enable/disable only basic memory monitoring
###########################################################################################
memory.monitor.forcebasic = false


###########################################################################################
# NOTE: All Ehcache properties below refer to the legacy tim-ehcache-1.3 and
# tim-ehcache-1.4 Terracotta Integration Modules.  These properties have no effect on the
# Ehache-Terracotta integration that was added in Ehcache 1.7.
###########################################################################################
#  Section                         : Ehcache
#  clusterAllCacheManagers         : Whether all CacheManager instances are auto-clustered by default,
#                                    i.e. whether static fields CacheManager.ALL_CACHE_MANAGERS and
#                                    CacheManager.singleton will be configured as roots.
#  logging.enabled                 : Enable/disable ehcache logging
#  evictor.logging.enabled         : Enable/disable evictor's logging
#  concurrency                     : Specifies the number of internal segments and gates the maximum
#                                    number of possible concurrent writers to the cache at one time.
#                                    There is memory and management overhead associated with each
#                                    segment. It is best for the hash function used in tim-ehcache
#                                    if the concurrency is a power of 2.
#  evictor.pool.size               : Thread pool size for evictor
#  global.eviction.enable          : Enable/disable global eviction from the cache
#  global.eviction.frequency       : Number of local eviction cycles after which global eviction may
#                                    start
#  global.eviction.segments        : Number of segments of objects for global evictor
#  global.eviction.rest.timeMillis : Sleep time between each segment's eviction
#  readLevel                       : The lock level used during cache read operations. Allowed values are
#                                    READ (default), CONCURRENT, and NO_LOCK.  NO_LOCK is only appropriate
#                                    in the case of read-only or single-threaded cache usage.
#  writeLevel                      : The lock level used during cache write operations.  Allowed values are
#                                    WRITE (default), and CONCURRENT.  WRITE is strongly recommended.
#  storageStrategy.dcv2.localcache.enabled
#                                  : The property enables/disables the local cache when ehcache has a
#                                    storage strategy of DCV2
#  storageStrategy.dcv2.perElementTTITTL.enabled
#                                  : If disabled then custom( or per element) tti/ttl is not considered when serverside
#                                    eviction is performed unless cache level tti/ttl is set. Enabling this has some
#                                    overhead in eviction when cache level tti/ttl is not set, compared when its disabled.
#  storageStrategy.dcv2.evictUnexpiredEntries.enabled
#                                  : When enabled, if maxElementsOnDisk is set and the cache overshoots it, elements will be
#                                    evicted irrespective of whether they are expired or not if enough expired elements
#                                    cant be found.
#  storageStrategy.dcv2.periodicEviction.enabled
#                                  : The property enables/disables the periodic eviction when ehcache has a
#                                    storage strategy of DCV2
#  storageStrategy.dcv2.pinSegments.enabled
#                                  : The property enables/disables the pinning of DCV2 segments in memory
#  storageStrategy.dcv2.eviction.overshoot
#                                  : % overshoot required to trigger capacity eviction
###########################################################################################
ehcache.clusterAllCacheManagers = true
ehcache.logging.enabled = false
ehcache.evictor.logging.enabled = false
ehcache.concurrency = 128
ehcache.evictor.pool.size = 1
ehcache.global.eviction.enable = true
ehcache.global.eviction.frequency = 10
ehcache.global.eviction.segments = 2
ehcache.global.eviction.rest.timeMillis = 10
ehcache.lock.readLevel = READ
ehcache.lock.writeLevel = WRITE
ehcache.storageStrategy.dcv2.localcache.enabled = true
ehcache.storageStrategy.dcv2.perElementTTITTL.enabled = false
ehcache.storageStrategy.dcv2.evictUnexpiredEntries.enabled = true
ehcache.storageStrategy.dcv2.periodicEviction.enabled = true
ehcache.storageStrategy.dcv2.eviction.overshoot = 15
#ehcache.invalidator.sleep =


###########################################################################################
# Section                           : Lock statistics
# lock.statistics.enabled           : Enables/disables lock statistics
# l1.lock.statistics.traceDepth     : Depth of locks given to L1s for gathering the statistics
# l1.lock.statistics.gatherInterval : Poll interval for gathering lock statistics
###########################################################################################
lock.statistics.enabled = false
l1.lock.statistics.traceDepth = 0
l1.lock.statistics.gatherInterval = 1

###########################################################################################
# Section           : Greedy Lease Lock
# enabled           : Enable/disable greedy locks grant from L2
# leaseTimeInMillis : Time for which greedy locks are given to L1 if more than one of them
#                     are contending for them
###########################################################################################
l2.lockmanager.greedy.locks.enabled = true
l2.lockmanager.greedy.lease.enabled = true
l2.lockmanager.greedy.lease.leaseTimeInMillis = 50

###########################################################################################
# Section       : TCP Settings
# tcpnodelay    : Enable/disable tcp packet batching
# keepalive     : Enable/disable tcp probe for running/broken connections
###########################################################################################
net.core.tcpnodelay = true
net.core.keepalive = false

###########################################################################################
# Section :  HealthChecker { server(l2)->client(l1), server(l2)->server(l2) (HA), client(l1)->server(l2) }
#  ping.enabled         - If true, healthchecker is enabled.
#  ping.idletime        - Connection idletime (in milliseconds), after which healthchecker
#                         starts its ping test.
#  ping.interval        - The interval (in milliseconds) between healthchecker sending ping
#                         messages to the peer node which doesn't reply to its previous msgs.
#  ping.probes          - Total number of ping messages to be sent to the peer node before
#                         concluding the peer is dead.
#  socketConnect        - If true, apart from above ping-probe cycle, healthcheker does extra
#                         check like socket connect (to detect long GC) to see if the peer has
#                         any traces of life left
#  socketConnectCount   - Max number of successful socket connect that healthcheker
#                         can trust. Beyond which, no socket connects will be
#                         attempted and peer node is tagged as dead.
#  socketConnectTimeout - Socket timeout (integer, in number of ping.interval) when
#                         connecting to the peer node. On timeout, healthchecker
#                         concludes peer node as dead irrespective of previous
#                         successful socket connects.
#  checkTime.enabled    - If true, checking time difference between hosts is enabled.
#  checkTime.interval   - The interval (in milliseconds) between healthchecker attempting
#                         to find any time difference between hosts.
#  checkTime.threshold  - The maximum allowed time difference (in milliseconds) between hosts.
#                         Healthchecker logs a warning message if the time difference exceeds this limit.
###########################################################################################
# L2 -> L1  :
# These settings will detect a network disconnect (like a cable pull) in 10 seconds and
#   will allow a 40 second GC in the L1
l2.healthcheck.l1.ping.enabled = true
l2.healthcheck.l1.ping.idletime = 5000
l2.healthcheck.l1.ping.interval = 1000
l2.healthcheck.l1.ping.probes = 3
l2.healthcheck.l1.socketConnect = true
l2.healthcheck.l1.socketConnectTimeout = 5
l2.healthcheck.l1.socketConnectCount = 10
l2.healthcheck.l1.checkTime.enabled = true
l2.healthcheck.l1.checkTime.interval = 300000
l2.healthcheck.l1.checkTime.threshold = 300000

# L2 -> L2  : Networked Active-Passive
# These settings will detect a network disconnect (like a cable pull) in 10 seconds but
#   will allow a 40 second GC in the L2
l2.healthcheck.l2.ping.enabled = true
l2.healthcheck.l2.ping.idletime = 5000
l2.healthcheck.l2.ping.interval = 1000
l2.healthcheck.l2.ping.probes = 3
l2.healthcheck.l2.socketConnect = true
l2.healthcheck.l2.socketConnectTimeout = 5
l2.healthcheck.l2.socketConnectCount = 10
l2.healthcheck.l2.checkTime.enabled = true
l2.healthcheck.l2.checkTime.interval = 300000
l2.healthcheck.l2.checkTime.threshold = 300000

# L1 -> L2  : Health check
# These settings will detect a network disconnect (like a cable pull) in 10 seconds but
#   will allow upto 50 seconds GC in the L2
# L1's CallbackPort Listener can be by assigned randomly by the operating system:
#   bindPort = 0
# L1's CallbackPort Listener can be disabled with the following property:
#   bindPort = -1
# L1's CallbackPort Listener can be configured with a list of port ranges. For example:
#   bindPort = 8000,8100-8110,9000-10000,45000
l1.healthcheck.l2.bindAddress = 0.0.0.0
l1.healthcheck.l2.bindPort = 0
l1.healthcheck.l2.ping.enabled = true
l1.healthcheck.l2.ping.idletime = 5000
l1.healthcheck.l2.ping.interval = 1000
l1.healthcheck.l2.ping.probes = 3
l1.healthcheck.l2.socketConnect = true
l1.healthcheck.l2.socketConnectTimeout = 5
l1.healthcheck.l2.socketConnectCount = 13
l1.healthcheck.l2.checkTime.enabled = true
l1.healthcheck.l2.checkTime.interval = 300000
l1.healthcheck.l2.checkTime.threshold = 300000

###########################################################################################
# Section :  TCMessage debug monitoring
#   tcm.monitor.enabled - If enabled the count and size of TC messages will be collected and logged
#   tcm.monitor.delay - The delay (in seconds) between reporting to the log
###########################################################################################
tcm.monitor.enabled = false
tcm.monitor.delay = 5

###########################################################################################
# Section :  HTTP
#   http.defaultservlet.enabled - If true, will serve files through embedded HTTP server
#   http.defaultservlet.attribute.aliases - If true, allows aliases like symlinks to be
#                                           followed while serving files
#   http.defaultservlet.attribute.dirallowed - If true, directory listings are returned if
#                                              no welcome file is found
###########################################################################################
http.defaultservlet.enabled = false;
http.defaultservlet.attribute.aliases = false;
http.defaultservlet.attribute.dirallowed = false;

###########################################################################################
# Section :  Remote JMX
#  l2.remotejmx.maxthreads                     - Maximum number of concurrent remote jmx operations permitted
#  l2.remotejmx.idletime                       - Idle timeout (in seconds) for remote jmx processing threads
#  l2.remotejmx.connect.timeout                - Timeout for performing jmx connection back to remote/L1 jmx mbean server
###########################################################################################
l2.remotejmx.maxthreads = 50
l2.remotejmx.idletime = 5
l2.remotejmx.connect.timeout = 30000

###########################################################################################
# Section :  Stats Printer
#  stats.printer.intervalInMillis              - Interval at which gathered stats are printed
###########################################################################################
stats.printer.intervalInMillis = 5000

###########################################################################################
# Section :  LicenseManager
# productkey.resource.path                       - path to product key on your classpath
# productkey.path                                - path to product key
###########################################################################################
#productkey.resource.path=
#productkey.path=

###########################################################################################
# l2.dump.on.exception.timeout - After get an uncaught exception, the server takes a dump. If the
#                 dump doesn't happen within this timeout the server will exit (in seconds).
###########################################################################################
l2.dump.on.exception.timeout = 30

###########################################################################################
# Section :  Dev console Settings
#   l2.operator.events.store      -   Number of operator events L2s will store to keep the history of the events
#   tc.time.sync.threshold        -   Number of second of tolerable system time difference between
#                                     two nodes of cluster beyond which and operator event will be thrown
#   l2.logs.store                 -   Number of logs L2s will store to keep the history of the logs
###########################################################################################
l2.operator.events.store = 100
tc.time.sync.threshold = 30
l2.logs.store = 1500

###########################################################################################
# Section: REST management Settings
#   management.rest.enabled       -   Enable or disable the management REST facilities
###########################################################################################
management.rest.enabled=true

###########################################################################################
# Section :  L1 Shutdown Settings
# l1.shutdown.threadgroup.gracetime - time allowed for termination of all threads in the
#                    TC thread group (in milliseconds).
# l1.shutdown.force.finalization    - call System.runFinalization() at the end of the L1 shutdown procedure.
###########################################################################################
l1.shutdown.threadgroup.gracetime = 30000
l1.shutdown.force.finalization = true

###########################################################################################
# Section :  OffHeap Settings
# allocation.slow            - Time allowed (ms) for chunk allocations before warning of potential page swapping.
# allocation.critical        - Time allowed (ms) for chunk allocations before warning of critical memory issues.
# allocation.critical.halt   - Whether to attempt to halt the JVM on a critical allocation situation.
# max.chunk.size             - The Allocator will try to start allocating chunks of this size.
#                                It will then reduce by factor of 2 if it can't allocate this big size.
# min.chunk.size             - The above process of allocation will continue until it reaches this size.
# object.initialDataSize       - initial data size in bytes for ObjectDB
# object.tableSize           - hashmap table size in numbers for ObjectDB
# object.concurrency        - hashmap segments in numbers for ObjectDB
# map.initialDataSize        - initial data size in bytes for MapsDB
# map.tableSize              - hashmap table size in numbers for MapsDB
# map.percentage              - percentage of offheap for mapsDB
###########################################################################################
l2.offHeap.allocation.slow = 1500
l2.offHeap.allocation.critical = 15000
l2.offHeap.allocation.critical.halt = true
l2.offHeap.map.concurrency = 1
#l2.offHeap.min.page.size = 4k
#l2.offHeap.max.page.size = 8m
l2.offHeap.map.tableSize = 128
# l2.offHeap.max.chunk.size = 512m
# l2.offHeap.min.chunk.size = 32m
# l2.offHeap.object.initialDataSize = 1m
# l2.offHeap.object.tableSize = 1m
# l2.offHeap.object.concurrency = 4k

###########################################################################################
# Section :  Search
# query.wait.for.txns     - wait for all current txns in the issuing node to complete before executing queries.
#              NOTE: if not defined, this will be based on the cache's consistency setting: false for eventual, true for strong
# use.commit.thread       - if true, always use a background thread to call lucene commit(). Setting to false will NEVER call commit
#                           and data durability and consistency is no longer guaranteed.
#              NOTE: if not defined, commit thread will be on for permanent store mode and off otherwise.
# passive.max.chunk       - maximum chunk size of network message when transferring search index data to passive
# passive.max.pending     - maximum number of un-ACK'd chunks to send to passive at any given time
# lucene.max.buffer       - maxium buffer size (in MB) for each lucene index writer
# lucene.max.boolean.clauses
#                         - sets the maximum number of terms allowed in the Or/And or InCollection search criteria; *USE WITH CAUTION*

# lucene.indexes.per.cache- The number of indexes that are created per cache
# l1.search.max.open.resultSets 
#                         - Maximum open paged results per L1, default is unlimited 
# l2.search.max.paged.resultSets
#                         - Maximum open paged results per L2, default is 1000 
# l2.search.max.result.pageSize 
#                         - Maximum result batch size for paged search queries, default is 10000
#
###########################################################################################
# search.query.wait.for.txns = true
# search.use.commit.thread = false
search.passive.max.chunk = 2097152
search.passive.max.pending = 8
search.lucene.use.ram.directory = false
search.lucene.use.offHeap.directory = false
search.lucene.max.buffer = 16.0
#search.lucene.mergefactor = 10
#search.lucene.maxBufferedDocs = -1
#search.lucene.maxMergeDocs = 2147483647
#search.lucene.disableStoredFieldCompression = false
#search.lucene.maxMergeThreads = 8
search.lucene.indexes.per.cache = 4
search.lucene.max.boolean.clauses = 1024

###########################################################################################
# Section : App groups
# appgroups.debug - enable.disable debug logging for app-groups
###########################################################################################
appgroups.debug = false


###########################################################################################
# Section : OffHeap File System
# offHeapFilesystem.chm.segments - number of segments for OffHeap CHM
# offHeapFilesystem.file.blockSize - granularity at which memory is allocated to each file in Bytes (must be a power of two)
# offHeapFileSystem.file.maxDataPageSize - maximum size of each page for OffHeap CHM in Bytes (must be a power of two and larger than blockSize)
###########################################################################################
offHeapFilesystem.chm.segments = 4
offHeapFilesystem.file.blockSize = 8192
offHeapFileSystem.file.maxDataPageSize = 262144

###########################################################################################
# Section :  BulkLoad Settings
# toolkit.bulkload.logging               - Enable logging for Bulkload
# toolkit.bulkload.minbatchbytesize      - Minimum batch size(default 5MB) send to L2 
# toolkit.bulkload.throttle.timeInmillis - Time in millis used for throttling
# toolkit.bulkload.throttle.threshold    - Maxmium size(default 10Mb) of buffer after which throttling will happend
###########################################################################################
toolkit.bulkload.logging = false
toolkit.bulkload.minbatchbytesize = 5242880
toolkit.bulkload.throttle.timeInmillis = 600
toolkit.bulkload.throttle.threshold = 10485760

###########################################################################################
# Section :  Version Settings
# version.compatibility.check - check version compatibility for client<->server and server<-> connections
###########################################################################################
version.compatibility.check = true



